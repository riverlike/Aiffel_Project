{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP04_Assignment_NewsClassifier.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 뉴스 카테고리 다중분류\n",
        "\n",
        "이번 프로젝트에서는 이전 LMS에서 진행하였던 뉴스 카테고리 다중분류문제를 여러가지 데이터셋에 대하여 적용해보고 모델이나 데이터셋에 따른 성능분석을 진행해보겠다.\n",
        "\n",
        "Dataset \n",
        "---\n",
        "- [로이터 뉴스](https://keras.io/api/datasets/reuters/)\n",
        " - 46가지 토픽으로 라벨이 달린 11,228개의 로이터 뉴스로 이루어진 데이터셋\n",
        " - 각 뉴스는 단어 인덱스의 시퀀스로 인코딩되어 있다.\n",
        "\n",
        "- 토픽 : 46개 (뉴스 카테고리)\n",
        " - 참고 : https://github.com/SteffenBauer/KerasTools/tree/master/Reuters_Analysis\n",
        " - category : https://liaison.reuters.com/tools/topic-codes\n",
        "```\n",
        "'cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead'\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YE8Bwrp8MlF1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "V51X60HLgxar"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "fh_pUwJXz8xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
      ],
      "metadata": {
        "id": "O6OO186Nzw7c"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
        "print('테스트 샘플의 수: {}'.format(len(x_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nCsL5vah4ii",
        "outputId": "9712a51b-b298-400b-e603-0a0c3af46468"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플의 수: 8982\n",
            "테스트 샘플의 수: 2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결측치 및 중복 데이터 확인"
      ],
      "metadata": {
        "id": "0Csso4Cf5cJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.Series(x_train)\n",
        "X_test = pd.Series(x_test)"
      ],
      "metadata": {
        "id": "UzIHrzQG7iGA"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isnull().sum(), X_test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkmvNDTY7TPQ",
        "outputId": "ad882973-3cfe-4fe2-fd13-f3e6752df2e1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.duplicated().sum(), X_test.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4-2ej9RFdNF",
        "outputId": "c46ef9a3-7060-404a-a2a7-6714c4510293"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(529, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로이터 뉴스 데이터셋에는 결측치는 없고 중복 데이터가 훈련셋에서 529건, 테스트셋에서 32건이 존재한다. 중복데이터만 따로 확인해보자."
      ],
      "metadata": {
        "id": "nW7oJ2nmlwgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dup = X_train[X_train.duplicated()]"
      ],
      "metadata": {
        "id": "lyzuYpccB-Y5"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dup.head()"
      ],
      "metadata": {
        "id": "fGxGEE5sFyb2",
        "outputId": "8002bc17-9b35-4d60-85cf-a4e877c7fb28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "841     [1, 53, 187, 15508, 14, 61, 16037, 341, 59, 24...\n",
              "855     [1, 53, 258, 26, 14, 134, 26, 39, 2228, 18, 14...\n",
              "893     [1, 4, 60, 5, 130, 40, 414, 1087, 95, 97, 68, ...\n",
              "987     [1, 53, 74, 155, 26, 14, 46, 196, 26, 39, 74, ...\n",
              "1090    [1, 53, 74, 142, 26, 14, 46, 279, 26, 39, 74, ...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_dup[987])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJSuI1F2EY-G",
        "outputId": "16851412-1dab-4caf-fe39-5a96626b8d56"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 53, 74, 155, 26, 14, 46, 196, 26, 39, 74, 2558, 18, 14, 46, 3232, 18, 86, 44, 8261, 18, 14, 44, 5020, 18, 17, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, v in enumerate(x_train):\n",
        "    if v == [1, 53, 74, 155, 26, 14, 46, 196, 26, 39, 74, 2558, 18, 14, 46, 3232, 18, 86, 44, 8261, 18, 14, 44, 5020, 18, 17, 12]:\n",
        "        print(\"index : {}, value: {}\".format(i,v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_CI2PVf8gPP",
        "outputId": "40e3c884-6d06-40b4-b1fe-8427e22eba48"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index : 204, value: [1, 53, 74, 155, 26, 14, 46, 196, 26, 39, 74, 2558, 18, 14, 46, 3232, 18, 86, 44, 8261, 18, 14, 44, 5020, 18, 17, 12]\n",
            "index : 987, value: [1, 53, 74, 155, 26, 14, 46, 196, 26, 39, 74, 2558, 18, 14, 46, 3232, 18, 86, 44, 8261, 18, 14, 44, 5020, 18, 17, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 사례처럼 204번째 뉴스와 987번의 뉴스는 동일한 내용으로 보고 첫번째 뉴스를 제외하고 중복된 뒤의 뉴스의 내용은 삭제하겠다."
      ],
      "metadata": {
        "id": "Cv-LeL0ElIdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.drop_duplicates(keep='first', inplace=True)\n",
        "X_test.drop_duplicates(keep='first', inplace=True)"
      ],
      "metadata": {
        "id": "r4mSBPOZ5fFj"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.duplicated().sum(), X_test.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IASJHh6l6ai",
        "outputId": "3845d381-a959-4bb7-c652-98812d77f523"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = X_train.to_numpy()\n",
        "x_test = X_test.to_numpy()"
      ],
      "metadata": {
        "id": "dx-impk_myVh"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
        "print('테스트 샘플의 수: {}'.format(len(x_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJt3Bo50l_Sp",
        "outputId": "abc64dde-6772-41c7-9b75-26a967ab8680"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플의 수: 8453\n",
            "테스트 샘플의 수: 2214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 데이터셋에서 중복 데이터를 제외하여 훈련 샘플의 수: 8982-> 8453건, 테스트 샘플의 수: 2246->2214건이 남았다."
      ],
      "metadata": {
        "id": "qg1AWfKqnIR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 뉴스 길이 확인"
      ],
      "metadata": {
        "id": "IGyP8ZjT5Vhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
        "print('훈련용 뉴스의 최소 길이 :{}'.format(min(len(l) for l in x_train)))\n",
        "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
        "\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "B5RzT-LT0mkR",
        "outputId": "12cbe968-8361-4388-8b41-413ec88905c2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 뉴스의 최대 길이 :2376\n",
            "훈련용 뉴스의 최소 길이 :13\n",
            "훈련용 뉴스의 평균 길이 :144.87448243227257\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련용 뉴스 문서에 길이는 13에서 2376까지의 분포로 평균길이는 약145이다. 막대그래프로 보았을때 문서의 길이가 500이상이 되었을때 샘플 분포가 적은것을 알수 있다. \n",
        "\n",
        "만약 RNN모델로 텍스트 분류를 진행한다면 훈련에 적절한 최대 문장의 길이를(위의 경우 500) 설정하고 길이보다 짧은 문서는 pad를 추가하여 수치화하는 과정을 가질것이다. \n",
        "\n",
        "하지만 본 프로젝트에서는 머신러닝과 TF-IDF를 활용하여 텍스트 분류를 진행할 것이므로 EDA는 여기까지 마치도록하자. \n",
        "\n"
      ],
      "metadata": {
        "id": "bMdctKEl0ryf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어사전 설정\n",
        "- reuters_word_index.json 파일을 제공\n",
        " - 단어와 정수 인덱스를 매핑한 딕셔너리"
      ],
      "metadata": {
        "id": "F6EMi3SjgTNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "id": "_0qufUBm5B07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f310d404-7510-4d59-cabf-2f685f1de776"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mdbl': 10996, 'fawc': 16260, 'degussa': 12089, 'woods': 8803, 'hanging': 13796, 'localized': 20672, }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 텍스트 시퀀스로 바꾸기위해 index_to_word사전을 역으로 구성해보자. 단 index 0,1,2에 대응하는 세가지 토큰도 word_to_index에 추가해주어야한다."
      ],
      "metadata": {
        "id": "ajo2jYj9sl6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = { index+3 : word for word, index in word_to_index.items() }\n",
        "\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token"
      ],
      "metadata": {
        "id": "qxsrIYSjscXD"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리시 중복값이 있었던 뉴스(204번째 뉴스)의 내용을 한번확인해보자. "
      ],
      "metadata": {
        "id": "FYoI_C1Oukha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_category = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']\n",
        "\n",
        "def get_category(label):\n",
        "    return news_category[label]\n",
        "\n",
        "print(x_train[204])\n",
        "print(' '.join([index_to_word[index] for index in x_train[204]]))\n",
        "print('News category:', get_category(y_train[204]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GULgC-cZuENo",
        "outputId": "36c39bd3-9c60-416d-c554-36260cf40421"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 53, 74, 155, 26, 14, 46, 196, 26, 39, 74, 2558, 18, 14, 46, 3232, 18, 86, 44, 8261, 18, 14, 44, 5020, 18, 17, 12]\n",
            "<sos> shr profit six cts vs loss 18 cts net profit 156 000 vs loss 212 000 revs 5 094 000 vs 5 669 000 reuter 3\n",
            "News category: coffee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "204번째 뉴스는 coffee카테고리에 속한다. 뉴스에서 증시나 금융정보가 중요한 만큼 숫자 데이터가 텍스트 데이터와 함께 토큰화된 점이 눈에 뛴다. 토큰화시 숫자는 3자리로 나누어 처리한것같다. \n",
        "\n",
        "다른 카테고리에 속하는 뉴스도 확인해보자."
      ],
      "metadata": {
        "id": "8qlGxcW7wjcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_word[index] for index in x_train[200]]))\n",
        "print('News category:', get_category(y_train[200]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_JCz5FGuizI",
        "outputId": "3717fbee-4c05-4c1f-c198-a40a6ab6769e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> japan's seasonally adjusted unemployment rate rose to a record 3 0 pct in january the worst since the government started compiling unemployment statistics under its current system in 1953 up from the previous record 2 9 pct in december the government's management and coordination agency said unemployment was up from 2 8 pct a year earlier unadjusted january unemployment totalled 1 82 mln people up from 1 61 mln in december and 1 65 mln a year earlier male unemployment in january remained at 2 9 pct equal to the second worst level set last december record male unemployement of 3 1 pct was set in july 1986 female unemployment in january remained at 3 0 pct equal to the record level marked in april august september and december last year january's record 3 0 pct unemployment rate mainly stemmed from loss of jobs in manufacturing industries particularly in export related firms due to the yen's continuing appreciation against the dollar officials said employment in manufacturing industries fell 380 000 from a year earlier to 14 30 mln including 1 83 mln employed in the textile industry down 190 000 from a year earlier and 1 06 mln in transport industries such as carmakers and shipbuilders down 170 000 reuter 3\n",
            "News category: jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일본의 실업상황 관련된 뉴스 같은데 jobs 카테고리에 속한다고 나와있다.\n",
        "\n",
        "위 데이터를 구성하는 방법으로 데이터셋을 로드하는 함수를 정의하고 실험을 진행해보겠다."
      ],
      "metadata": {
        "id": "_DmSn2C0y0CL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리"
      ],
      "metadata": {
        "id": "ShXCiJzD3p32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "R5eL87sO3ohZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data load 함수 정의\n",
        "1. 최빈도 단어들중 num_words만큼 데이터셋을 구성\n",
        "2. 정수형 데이터를 텍스트 데이터로 변환\n",
        "3. 사이킷런의 CountVectorizer()을 사용하여 Document Term Matrix(DTM) 구성\n",
        "4. 사이킷런의 TfidfTransformer() 을 사용하여 DTM을 TF-IDF Matrix로 변환한후 리턴"
      ],
      "metadata": {
        "id": "fOgizvAdisjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "def load_news_data(num_words):\n",
        "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2)\n",
        "\n",
        "   #중복 제거\n",
        "    X_train = pd.Series(x_train)\n",
        "    X_test = pd.Series(x_test)\n",
        "    X_train.drop_duplicates(keep='first', inplace=True)\n",
        "    X_test.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "    df_train = pd.DataFrame(x_train, columns=['text'])\n",
        "    df_test = pd.DataFrame(x_test, columns=['text'])\n",
        "\n",
        "    #리스트 타입은 mutable 하여 중복 체크가 되지않아 str타입으로 변경한 컬럼을 따로 추가한다.\n",
        "    df_train['str_text'] = df_train.text.astype(str)\n",
        "    df_test['str_text'] = df_test.text.astype(str)\n",
        "    df_train['category'] = y_train\n",
        "    df_test['category'] = y_test\n",
        "\n",
        "    #중복 제거\n",
        "    df_train.drop_duplicates(['str_text'], keep='first', inplace=True)\n",
        "    df_test.drop_duplicates(['str_text'], keep='first', inplace=True)\n",
        "\n",
        "    #다시 넘파일 배열로 변경시켜준다.\n",
        "    x_train = df_train.text.to_numpy()\n",
        "    y_train = df_train.category.to_numpy()\n",
        "    x_test = df_test.text.to_numpy()\n",
        "    y_test = df_test.category.to_numpy()\n",
        "\n",
        "    decoded = []\n",
        "    for i in range(len(x_train)):\n",
        "        t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "        decoded.append(t)\n",
        "    x_train = decoded\n",
        "\n",
        "    decoded = []\n",
        "    for i in range(len(x_test)):\n",
        "        t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "        decoded.append(t)\n",
        "    x_test = decoded\n",
        "\n",
        "    print('load data :',  len(x_train), len(x_test)) \n",
        "\n",
        "    dtmvector = CountVectorizer()\n",
        "    tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "    x_train_dtm = dtmvector.fit_transform(x_train)    #훈련 데이터를 DTM으로 변환\n",
        "    tfidfv_train = tfidf_transformer.fit_transform(x_train_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "    x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
        "    tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "    \n",
        "    print('transformer data :', tfidfv_train.shape, tfidfv_test.shape) \n",
        "\n",
        "    return tfidfv_train, y_train, tfidfv_test, y_test"
      ],
      "metadata": {
        "id": "-kZz0J15HtwQ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## f1- score 함수\n",
        "\n",
        "- keras에서 f1-score와 관련 API를 지원하지않으므로  따로 f1-score를 구하는 함수를 정의해주고 딥러닝 모델 훈련시 Metric에 추가하여 참조하도록했다."
      ],
      "metadata": {
        "id": "HQg-PM1y3jk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return _f1score\n"
      ],
      "metadata": {
        "id": "g48pmXruzkh7"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#성능 지표 저장을 위한 데이터프레임 변수\n",
        "columns = [\"Acc\", \"F1\"]\n",
        "index = [\"Naive Bayes\", \"ComplementNB\", \"LogisticRegression\", \"Support Vector Machine\",\\\n",
        "         \"Decision Tree\", \"Random Forest\", \"GradientBoosting\", \"Voting\", 'DNN']"
      ],
      "metadata": {
        "id": "EBq0GVgMRKDl"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nb = MultinomialNB()\n",
        "model_cb = ComplementNB()\n",
        "model_lr = LogisticRegression(C=10000, penalty='l2')\n",
        "model_svc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
        "model_dt = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
        "model_rf = RandomForestClassifier(n_estimators=5, random_state=0)\n",
        "model_gb = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "model_dict = {}\n",
        "model_dict[index[0]] = model_nb\n",
        "model_dict[index[1]] = model_cb\n",
        "model_dict[index[2]] = model_lr\n",
        "model_dict[index[3]] = model_svc\n",
        "model_dict[index[4]] = model_dt\n",
        "model_dict[index[5]] = model_rf\n",
        "model_dict[index[6]] = model_gb"
      ],
      "metadata": {
        "id": "R3MixIRYweEG"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신러닝 알고리즘중 위 7개 모델에 대하여 훈련, 테스트를 진행하는 함수를 정의 하겠다. 모델 훈련, 테스트 결과를 저장할 dataframe정보도 함께 넘겨주어야한다.\n",
        "\n",
        "보팅모델은 7개 모델의 결과에서 성능이 좋은 3개의 모델을 사용하여 따로 구성하겠다. "
      ],
      "metadata": {
        "id": "9NTqqwoA08Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7개 ML 모델 훈련및 테스트 함수\n",
        "def excute_train_test(x_train, y_train, x_test, y_test, df_scroe):    \n",
        "    for model_name, model in model_dict.items():\n",
        "        model.fit(x_train, y_train) #훈련\n",
        "        y_pred = model.predict(x_test) #예측\n",
        "        acc = accuracy_score(y_test, y_pred) #정확도 평가\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted') #f1-score 평가\n",
        "        df_scroe.loc[df_scroe.index == model_name] = (acc, f1) #평가 점수 설정\n",
        "        print(model_name, ':', acc, f1)"
      ],
      "metadata": {
        "id": "vHAq9ntW1n_x"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting 훈련및 테스트 함수\n",
        "def excute_voting_train_test(x_train, y_train, x_test, y_test, df_scroe, estimators):\n",
        "    model_vt = VotingClassifier(estimators=estimators,\n",
        "                voting='soft', n_jobs=-1)\n",
        "    model_vt.fit(x_train, y_train)#훈련\n",
        "    y_pred = model_vt.predict(x_test) #예측\n",
        "    acc = accuracy_score(y_test, y_pred) #정확도 평가\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted') #f1-score 평가\n",
        "    df_scroe.loc[df_scroe.index == 'Voting'] = (acc, f1)#평가 점수 설정\n",
        "    print('Voting', ':', acc, f1)"
      ],
      "metadata": {
        "id": "NLPPiBUVBV-r"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f315rpvHBVJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "csr_matrix(압축 희소 행렬)을 딥러닝 모델에 학습시키면 에러가 발생하므로 넘파이 행렬로 변경해주는 과정이 필요하다.\n",
        "\n",
        "- scipy.sparse.csr_matrix.todense() 메소드\n"
      ],
      "metadata": {
        "id": "NnGIqz8b87nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 모델 훈련및 테스트 함수\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def excute_dnn_train_test(x_train, y_train, x_test, y_test, df_scroe): \n",
        "    # sparse matrix -> dense array로 변경\n",
        "    x_train_ds = x_train.todense()\n",
        "    x_test_ds = x_test.todense()\n",
        "\n",
        "    CLASSES = 46\n",
        "    input_dim = x_train_ds.shape[1] \n",
        "\n",
        "    model_nn = keras.Sequential()\n",
        "    model_nn.add(keras.layers.Dense(256, input_dim=input_dim, activation='relu'))\n",
        "    model_nn.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model_nn.add(keras.layers.Dense(46, activation='softmax'))\n",
        "\n",
        "    METRICS = ['accuracy', f1score]\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, min_delta=0.05) #val_loss 관찰 # 3epoch 동안 손실이 0.05이상 개선되지 않을 경우 훈련 중지\n",
        "\n",
        "    model_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=METRICS)\n",
        "    model_nn.fit(x_train_ds, y_train_10000, validation_split=0.2, epochs=5, callbacks=[early_stopping])\n",
        "\n",
        "    _loss, _acc, _f1score = model_nn.evaluate(x_test_ds, y_test, verbose=2)\n",
        "    df_scroe.loc[df_scroe.index == 'DNN'] = (_acc, _f1score)"
      ],
      "metadata": {
        "id": "xLKSek9g8t65"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실험 방법\n",
        "\n",
        "**데이터셋**\n",
        "\n",
        "1. 빈도수 상위 10000개 : 이전 LMS에서 진행했던 데이터셋\n",
        "2. 모든 단어 - None\n",
        "3. 빈도수 상위 7500개\n",
        "3. 빈도수 상위 5000개\n",
        "4. 빈도수 상위 2500개\n",
        "\n",
        "**사용할 모델**\n",
        "- ML 모델\n",
        " - 나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅\n",
        "- 딥러닝 모델 \n"
      ],
      "metadata": {
        "id": "V6wOR9eU4h-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 데이터셋 - Vocabulary size = 10000\n",
        "\n",
        "이전 LMS에서 진행했던 10000개의 단어로 구성된 뉴스 데이터셋으로 훈련, 테스트를 진행해보겠다. LMS와 다른점은 중복을 제거했다는 점이다."
      ],
      "metadata": {
        "id": "DqMgURnw0ldN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_10000 = pd.DataFrame(None, index=index, columns=columns) # 모델별 성능 지표 저장 \n",
        "\n",
        "x_train_10000, y_train_10000, x_test_10000, y_test_10000 = load_news_data(10000)\n",
        "excute_train_test(x_train_10000, y_train_10000, x_test_10000, y_test_10000, df_score_10000)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzi-Bh_ICTrL",
        "outputId": "b97e7b4e-5e6a-483a-d020-d321e98b2ec7"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes : 0.6558265582655827 0.5732800811798514\n",
            "ComplementNB : 0.7750677506775068 0.7494529368479081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression : 0.8139114724480578 0.809521241932279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine : 0.7795844625112918 0.7755128612921335\n",
            "Decision Tree : 0.6201445347786811 0.5766074276420602\n",
            "Random Forest : 0.6802168021680217 0.6528981463659351\n",
            "GradientBoosting : 0.7728093947606143 0.7696990010475626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LMS에서 성능과 비교했을때 정확도 지표들이 NB, CNB는 비슷했고, 나머지모델들에 대해서는 1%가량 높게 나왔다. 중복을 제거한 데이터셋이 어느정도 성능에 기여하는 면이 있다고 보고 이대로 실험을 진행해도 좋겠다.\n",
        "\n",
        "Voting 모델에 대한 훈련과 테스트도 함께 진행해보자.\n",
        "- 보팅모델은 위 결과에서 성능이 좋은 3개의 모델을 사용하여 구성하겠다.  \n",
        " - LogisticRegression, ComplementNB, LinearSVC(제외), GradientBoostingClassifier\n",
        "- 성능면에서 LinearSVC 모델이 좋게 나왔지만 LinearSVC는 각카테고리별 예측확률을 제공하지않아 soft 보팅에 사용할수없어 제외하였다."
      ],
      "metadata": {
        "id": "41wbrpgBHCim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators=[('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "             ('cb', ComplementNB()), ('gbc', GradientBoostingClassifier(random_state=0)) ]\n",
        "\n",
        "excute_voting_train_test(x_train_10000, y_train_10000, x_test_10000, y_test_10000, df_score_10000, estimators)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YuFYzH9wBcl",
        "outputId": "180572e3-d901-42b0-ea7a-aa287c7c03ad"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting : 0.8229448961156278 0.8196364293036051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excute_dnn_train_test(x_train_10000, y_train_10000, x_test_10000, y_test_10000, df_score_10000)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThKiuxpl8Zm8",
        "outputId": "72964260-2ca2-4351-ba9c-9c9ff81d5936"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "212/212 [==============================] - 4s 14ms/step - loss: 1.6531 - accuracy: 0.6189 - f1score: 0.6391 - val_loss: 0.9669 - val_accuracy: 0.7658 - val_f1score: 0.8639\n",
            "Epoch 2/5\n",
            "212/212 [==============================] - 3s 15ms/step - loss: 0.6984 - accuracy: 0.8373 - f1score: 0.8956 - val_loss: 0.7233 - val_accuracy: 0.8285 - val_f1score: 0.8963\n",
            "Epoch 3/5\n",
            "212/212 [==============================] - 4s 17ms/step - loss: 0.3077 - accuracy: 0.9342 - f1score: 0.9488 - val_loss: 0.6517 - val_accuracy: 0.8504 - val_f1score: 0.9325\n",
            "Epoch 4/5\n",
            "212/212 [==============================] - 3s 16ms/step - loss: 0.1149 - accuracy: 0.9787 - f1score: 0.9823 - val_loss: 0.6498 - val_accuracy: 0.8457 - val_f1score: 0.9481\n",
            "70/70 - 0s - loss: 0.9749 - accuracy: 0.8008 - f1score: 0.9465 - 344ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) 데이터셋 - Vocabulary size = None"
      ],
      "metadata": {
        "id": "YVAIxJJftTQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_all = pd.DataFrame(None, index=index, columns=columns) # 모델별 성능 지표 저장 \n",
        "\n",
        "x_train_all, y_train_all, x_test_all, y_test_all = load_news_data(None)\n",
        "excute_train_test(x_train_all, y_train_all, x_test_all, y_test_all, df_score_all)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX_qlzKQtSIZ",
        "outputId": "7eac65fb-2cf3-4262-85be-ea0ddd719ec5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data : 8453 2214\n",
            "transformer data : (8453, 26506) (2214, 26506)\n",
            "Naive Bayes : 0.5984643179765131 0.5029231085851672\n",
            "ComplementNB : 0.7646793134598012 0.7326788250046982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression : 0.8134598012646793 0.8088907179060477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine : 0.7881662149954833 0.7846498291949523\n",
            "Decision Tree : 0.6345980126467932 0.6111470758748561\n",
            "Random Forest : 0.6508581752484192 0.6229052972298259\n",
            "GradientBoosting : 0.7719060523938572 0.7687850153955653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators=[('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "             ('cb', ComplementNB()), ('gbc', GradientBoostingClassifier(random_state=0)) ]\n",
        "\n",
        "excute_voting_train_test(x_train_all, y_train_all, x_test_all, y_test_all, df_score_all, estimators)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMuooX-8BC8M",
        "outputId": "c0a3a87f-eb9c-4d16-d7f8-f38496127230"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting : 0.8229448961156278 0.8186520936114796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excute_dnn_train_test(x_train_all, y_train_all, x_test_all, y_test_all, df_score_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjHxcGRBCvK7",
        "outputId": "c5f765e8-21bb-4cb1-dafd-a625e672d214"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "212/212 [==============================] - 7s 29ms/step - loss: 1.6415 - accuracy: 0.6224 - f1score: 0.6328 - val_loss: 0.9764 - val_accuracy: 0.7670 - val_f1score: 0.8502\n",
            "Epoch 2/5\n",
            "212/212 [==============================] - 6s 27ms/step - loss: 0.6596 - accuracy: 0.8477 - f1score: 0.8953 - val_loss: 0.7383 - val_accuracy: 0.8220 - val_f1score: 0.9137\n",
            "Epoch 3/5\n",
            "212/212 [==============================] - 6s 27ms/step - loss: 0.2475 - accuracy: 0.9510 - f1score: 0.9588 - val_loss: 0.6379 - val_accuracy: 0.8522 - val_f1score: 0.9273\n",
            "Epoch 4/5\n",
            "212/212 [==============================] - 6s 27ms/step - loss: 0.0789 - accuracy: 0.9874 - f1score: 0.9870 - val_loss: 0.6287 - val_accuracy: 0.8551 - val_f1score: 0.9476\n",
            "70/70 - 1s - loss: 0.9563 - accuracy: 0.8071 - f1score: 0.9465 - 592ms/epoch - 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) 데이터셋 - Vocabulary size = 7500"
      ],
      "metadata": {
        "id": "jT8-XgsCcbBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_7500 = pd.DataFrame(None, index=index, columns=columns) # 모델별 성능 지표 저장 \n",
        "\n",
        "x_train_7500, y_train_7500, x_test_7500, y_test_7500 = load_news_data(7500)\n",
        "excute_train_test(x_train_7500, y_train_7500, x_test_7500, y_test_7500, df_score_7500)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU_uU0Q4b3YZ",
        "outputId": "0eef8450-46b3-4eae-c7b5-aa5183fe3d52"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data : 8452 2214\n",
            "transformer data : (8452, 7296) (2214, 7296)\n",
            "Naive Bayes : 0.6653116531165312 0.585773421461886\n",
            "ComplementNB : 0.7728093947606143 0.7480028713138225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression : 0.8130081300813008 0.8089560090272443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine : 0.7886178861788617 0.7838669438153377\n",
            "Decision Tree : 0.6264679313459801 0.5825582919322535\n",
            "Random Forest : 0.6775067750677507 0.6491907628107406\n",
            "GradientBoosting : 0.7673893405600722 0.7642015862163347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators=[('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "             ('cb', ComplementNB()), ('gbc', GradientBoostingClassifier(random_state=0)) ]\n",
        "\n",
        "excute_voting_train_test(x_train_7500, y_train_7500, x_test_7500, y_test_7500, df_score_7500, estimators)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjIyfaEvcwRm",
        "outputId": "344da203-c808-4db3-a22d-83ae5b948a19"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting : 0.8215898825654924 0.8188925479141458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excute_dnn_train_test(x_train_7500, y_train_7500, x_test_7500, y_test_7500, df_score_7500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOXUi87mcv9l",
        "outputId": "b0520a3e-2869-44b9-c684-5b246250f6df"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 2.2484 - accuracy: 0.4446 - f1score: 0.4917 - val_loss: 2.7649 - val_accuracy: 0.2768 - val_f1score: 0.6674\n",
            "Epoch 2/5\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 1.6380 - accuracy: 0.5822 - f1score: 0.7464 - val_loss: 2.9823 - val_accuracy: 0.2413 - val_f1score: 0.7471\n",
            "Epoch 3/5\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 1.1373 - accuracy: 0.7029 - f1score: 0.8290 - val_loss: 3.4467 - val_accuracy: 0.2318 - val_f1score: 0.8080\n",
            "70/70 - 0s - loss: 1.3206 - accuracy: 0.6631 - f1score: 0.8138 - 267ms/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) 데이터셋 - Vocabulary size = 5000"
      ],
      "metadata": {
        "id": "OYHGxXjbtcwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_5000 = pd.DataFrame(None, index=index, columns=columns) # 모델별 성능 지표 저장 \n",
        "\n",
        "x_train_5000, y_train_5000, x_test_5000, y_test_5000 = load_news_data(5000)\n",
        "excute_train_test(x_train_5000, y_train_5000, x_test_5000, y_test_5000, df_score_5000)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzeZSsAFtSFU",
        "outputId": "06363f03-a150-4ac3-aaef-10a9e5fcd11c"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data : 8452 2214\n",
            "transformer data : (8452, 4867) (2214, 4867)\n",
            "Naive Bayes : 0.6725383920505872 0.5980940294490975\n",
            "ComplementNB : 0.7732610659439928 0.7476311622462234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression : 0.8071364046973803 0.8025318360667885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine : 0.7773261065943993 0.774132259282198\n",
            "Decision Tree : 0.6300813008130082 0.5834011675677825\n",
            "Random Forest : 0.6838301716350497 0.6564862518826285\n",
            "GradientBoosting : 0.7705510388437218 0.768656012511734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators=[('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "             ('cb', ComplementNB()), ('gbc', GradientBoostingClassifier(random_state=0)) ]\n",
        "\n",
        "excute_voting_train_test(x_train_5000, y_train_5000, x_test_5000, y_test_5000, df_score_5000, estimators)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEnYV1MdC-XZ",
        "outputId": "d8ebd24a-b251-4cf4-951c-6278c1c837b1"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting : 0.8197831978319783 0.8171697839357912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excute_dnn_train_test(x_train_5000, y_train_5000, x_test_5000, y_test_5000, df_score_5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSbTcgjUC-Ii",
        "outputId": "d57de3a5-a8fc-4932-8be1-01466f90b77c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "212/212 [==============================] - 3s 10ms/step - loss: 2.2464 - accuracy: 0.4382 - f1score: 0.4906 - val_loss: 2.7472 - val_accuracy: 0.2839 - val_f1score: 0.6287\n",
            "Epoch 2/5\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 1.7079 - accuracy: 0.5686 - f1score: 0.7250 - val_loss: 2.8947 - val_accuracy: 0.2578 - val_f1score: 0.7264\n",
            "Epoch 3/5\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 1.3113 - accuracy: 0.6582 - f1score: 0.8044 - val_loss: 3.2949 - val_accuracy: 0.2472 - val_f1score: 0.7956\n",
            "70/70 - 0s - loss: 1.2708 - accuracy: 0.6721 - f1score: 0.8086 - 216ms/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5) 데이터셋 - Vocabulary size = 2500"
      ],
      "metadata": {
        "id": "1S7Ew8z5tfFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_2500 = pd.DataFrame(None, index=index, columns=columns) # 모델별 성능 지표 저장 \n",
        "\n",
        "x_train_2500, y_train_2500, x_test_2500, y_test_2500 = load_news_data(2500)\n",
        "excute_train_test(x_train_2500, y_train_2500, x_test_2500, y_test_2500, df_score_2500)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1P7hTAtSCE",
        "outputId": "64b5d259-9e14-45c0-8021-a8403523dcf1"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data : 8452 2214\n",
            "transformer data : (8452, 2430) (2214, 2430)\n",
            "Naive Bayes : 0.6878952122854561 0.6284657660656189\n",
            "ComplementNB : 0.7610659439927733 0.7327923173721271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression : 0.7953929539295393 0.7900761552317107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine : 0.7570009033423668 0.7539242118341188\n",
            "Decision Tree : 0.6242095754290876 0.5843968375655397\n",
            "Random Forest : 0.7073170731707317 0.6835215646043322\n",
            "GradientBoosting : 0.7669376693766937 0.7626622073073209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators=[('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "             ('cb', ComplementNB()), ('gbc', GradientBoostingClassifier(random_state=0)) ]\n",
        "\n",
        "excute_voting_train_test(x_train_2500, y_train_2500, x_test_2500, y_test_2500, df_score_2500, estimators)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kng5JNGFXbAU",
        "outputId": "9256bfcf-dfdd-427a-adb8-1ab7afcfa916"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting : 0.8102981029810298 0.8062522467501312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excute_dnn_train_test(x_train_2500, y_train_2500, x_test_2500, y_test_2500, df_score_2500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtyTLuNMYDWz",
        "outputId": "54b621d3-dcb1-4e0e-848d-513559fb3b97"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "212/212 [==============================] - 2s 7ms/step - loss: 2.2510 - accuracy: 0.4461 - f1score: 0.5000 - val_loss: 2.7246 - val_accuracy: 0.2431 - val_f1score: 0.6385\n",
            "Epoch 2/5\n",
            "212/212 [==============================] - 1s 6ms/step - loss: 1.7729 - accuracy: 0.5529 - f1score: 0.7211 - val_loss: 2.8802 - val_accuracy: 0.2484 - val_f1score: 0.7057\n",
            "Epoch 3/5\n",
            "212/212 [==============================] - 1s 5ms/step - loss: 1.4936 - accuracy: 0.6156 - f1score: 0.7817 - val_loss: 3.0188 - val_accuracy: 0.2354 - val_f1score: 0.7413\n",
            "70/70 - 0s - loss: 1.2581 - accuracy: 0.7082 - f1score: 0.7300 - 158ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실험 결과\n",
        "\n",
        "데이터셋에 따른 모델별 평가 점수를 알아보자."
      ],
      "metadata": {
        "id": "HU4EWiABDfwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋의 사이즈별로 나누어진 점수정보를 모으겠다. \n",
        "dfs = {'All' : df_score_all, '10000' : df_score_10000, '7500': df_score_7500, '5000': df_score_5000, '2500': df_score_2500}\n",
        "df_scores = pd.concat(dfs.values(), axis=1, keys=dfs.keys())\n",
        "df_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "C-iIZfSXG0po",
        "outputId": "5d58165d-23fb-4965-df49-c6843e8c4cfd"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             All               10000                7500  \\\n",
              "                             Acc        F1       Acc        F1       Acc   \n",
              "Naive Bayes             0.598464  0.502923  0.655827   0.57328  0.665312   \n",
              "ComplementNB            0.764679  0.732679  0.775068  0.749453  0.772809   \n",
              "LogisticRegression       0.81346  0.808891  0.813911  0.809521  0.813008   \n",
              "Support Vector Machine  0.788166   0.78465  0.779584  0.775513  0.788618   \n",
              "Decision Tree           0.634598  0.611147  0.620145  0.576607  0.626468   \n",
              "Random Forest           0.650858  0.622905  0.680217  0.652898  0.677507   \n",
              "GradientBoosting        0.771906  0.768785  0.772809  0.769699  0.767389   \n",
              "Voting                  0.822945  0.818652  0.822945  0.819636   0.82159   \n",
              "DNN                     0.807136  0.946471  0.800813  0.946465  0.663053   \n",
              "\n",
              "                                      5000                2500            \n",
              "                              F1       Acc        F1       Acc        F1  \n",
              "Naive Bayes             0.585773  0.672538  0.598094  0.687895  0.628466  \n",
              "ComplementNB            0.748003  0.773261  0.747631  0.761066  0.732792  \n",
              "LogisticRegression      0.808956  0.807136  0.802532  0.795393  0.790076  \n",
              "Support Vector Machine  0.783867  0.777326  0.774132  0.757001  0.753924  \n",
              "Decision Tree           0.582558  0.630081  0.583401   0.62421  0.584397  \n",
              "Random Forest           0.649191   0.68383  0.656486  0.707317  0.683522  \n",
              "GradientBoosting        0.764202  0.770551  0.768656  0.766938  0.762662  \n",
              "Voting                  0.818893  0.819783   0.81717  0.810298  0.806252  \n",
              "DNN                     0.813835  0.672087  0.808603   0.70822  0.729962  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a0a3888-6e1f-41df-92a9-d1086eefc8bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">All</th>\n",
              "      <th colspan=\"2\" halign=\"left\">10000</th>\n",
              "      <th colspan=\"2\" halign=\"left\">7500</th>\n",
              "      <th colspan=\"2\" halign=\"left\">5000</th>\n",
              "      <th colspan=\"2\" halign=\"left\">2500</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.598464</td>\n",
              "      <td>0.502923</td>\n",
              "      <td>0.655827</td>\n",
              "      <td>0.57328</td>\n",
              "      <td>0.665312</td>\n",
              "      <td>0.585773</td>\n",
              "      <td>0.672538</td>\n",
              "      <td>0.598094</td>\n",
              "      <td>0.687895</td>\n",
              "      <td>0.628466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ComplementNB</th>\n",
              "      <td>0.764679</td>\n",
              "      <td>0.732679</td>\n",
              "      <td>0.775068</td>\n",
              "      <td>0.749453</td>\n",
              "      <td>0.772809</td>\n",
              "      <td>0.748003</td>\n",
              "      <td>0.773261</td>\n",
              "      <td>0.747631</td>\n",
              "      <td>0.761066</td>\n",
              "      <td>0.732792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.81346</td>\n",
              "      <td>0.808891</td>\n",
              "      <td>0.813911</td>\n",
              "      <td>0.809521</td>\n",
              "      <td>0.813008</td>\n",
              "      <td>0.808956</td>\n",
              "      <td>0.807136</td>\n",
              "      <td>0.802532</td>\n",
              "      <td>0.795393</td>\n",
              "      <td>0.790076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <td>0.788166</td>\n",
              "      <td>0.78465</td>\n",
              "      <td>0.779584</td>\n",
              "      <td>0.775513</td>\n",
              "      <td>0.788618</td>\n",
              "      <td>0.783867</td>\n",
              "      <td>0.777326</td>\n",
              "      <td>0.774132</td>\n",
              "      <td>0.757001</td>\n",
              "      <td>0.753924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.634598</td>\n",
              "      <td>0.611147</td>\n",
              "      <td>0.620145</td>\n",
              "      <td>0.576607</td>\n",
              "      <td>0.626468</td>\n",
              "      <td>0.582558</td>\n",
              "      <td>0.630081</td>\n",
              "      <td>0.583401</td>\n",
              "      <td>0.62421</td>\n",
              "      <td>0.584397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.650858</td>\n",
              "      <td>0.622905</td>\n",
              "      <td>0.680217</td>\n",
              "      <td>0.652898</td>\n",
              "      <td>0.677507</td>\n",
              "      <td>0.649191</td>\n",
              "      <td>0.68383</td>\n",
              "      <td>0.656486</td>\n",
              "      <td>0.707317</td>\n",
              "      <td>0.683522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoosting</th>\n",
              "      <td>0.771906</td>\n",
              "      <td>0.768785</td>\n",
              "      <td>0.772809</td>\n",
              "      <td>0.769699</td>\n",
              "      <td>0.767389</td>\n",
              "      <td>0.764202</td>\n",
              "      <td>0.770551</td>\n",
              "      <td>0.768656</td>\n",
              "      <td>0.766938</td>\n",
              "      <td>0.762662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Voting</th>\n",
              "      <td>0.822945</td>\n",
              "      <td>0.818652</td>\n",
              "      <td>0.822945</td>\n",
              "      <td>0.819636</td>\n",
              "      <td>0.82159</td>\n",
              "      <td>0.818893</td>\n",
              "      <td>0.819783</td>\n",
              "      <td>0.81717</td>\n",
              "      <td>0.810298</td>\n",
              "      <td>0.806252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.807136</td>\n",
              "      <td>0.946471</td>\n",
              "      <td>0.800813</td>\n",
              "      <td>0.946465</td>\n",
              "      <td>0.663053</td>\n",
              "      <td>0.813835</td>\n",
              "      <td>0.672087</td>\n",
              "      <td>0.808603</td>\n",
              "      <td>0.70822</td>\n",
              "      <td>0.729962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a0a3888-6e1f-41df-92a9-d1086eefc8bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a0a3888-6e1f-41df-92a9-d1086eefc8bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a0a3888-6e1f-41df-92a9-d1086eefc8bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정리."
      ],
      "metadata": {
        "id": "jtfE0yRgG1YG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번프로젝트에서 단어사전 사이즈(vocab size)별로 데이터셋을 구성하여 뉴스 카테고리 분류를 진행해보았다. 데이터중 특정 클래스의 분포가 많아 불균형이 심해 훈련과정이 잘 진행될지 의문이였는데, F1-socre 가 Voting을 통해 80%이상 확보되어 분류테스크를 잘 수행할 수 있었다.\n",
        "\n",
        "- Voting 모델 기준으로 vocab size가 줄어들수록 정확도는 줄어들었으며 F1스코어는 vocab size를 전체 단어로 잡았을때 보다 10000개로 잡았을때 점수가 높았다. \n",
        "\n",
        "- 딥러닝 모델은 레이어 3개로만 진행했을때 GradientBoosting보다 정확도 , F1스코어가 더 좋게 나왔으며 vocab size가 줄어들수록 F1스코어가 급격하게 떨어졌다.\n",
        "\n",
        "- 단일모델로는 LogisticRegression 모델이 정확도,  F1스코어의 점수가 높았으며 vocab size가 줄어들어도 성능이 유지되는 점이 신기했다. 보팅에 LogisticRegression을 사용하여 보팅모델의 성능도 비슷한 수준으로 유지되는것 같다. \n"
      ],
      "metadata": {
        "id": "prPt5Jl6Ggs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference\n",
        "- [f1 score](https://wikidocs.net/83933)\n",
        "- sparse-matrix-length-is-ambiguous[https://stackoverflow.com/questions/55104059/]\n",
        "- https://keras.io/ko/datasets/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dXfNvp5Kh4Nb"
      }
    }
  ]
}
